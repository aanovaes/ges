{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f75e2d9-11d3-4092-a5ff-45aa84decd84",
   "metadata": {},
   "source": [
    "# Projeto de Detecção de Defeitos em Chapas de Granito com YOLOv8\n",
    "**Dissertação de Mestrado**\n",
    "\n",
    "**Autor**: Alexsander Alves Novaes\n",
    "\n",
    "**Orientador**: Prof. Dr. Daniel Cruz Cavalieri\n",
    "\n",
    "**Instituição**: IFES\n",
    "\n",
    "**Data**: Jul/2024 \n",
    "\n",
    "## Contexto\n",
    "\n",
    "Este projeto visa a detecção automática de defeitos em chapas de granito utilizando o modelo YOLOv8. O objetivo é desenvolver um pipeline completo e replicável para identificar diferentes tipos de defeitos em imagens de chapas de granito. Este documento é parte integrante da dissertação de mestrado e contém todos os passos necessários para executar e replicar o projeto, desde a configuração do ambiente até o treinamento do modelo.\n",
    "\n",
    "## Objetivos\n",
    "\n",
    "1. **Configuração do Ambiente**: Carregar configurações e preparar o ambiente de trabalho.\n",
    "2. **Download do Dataset**: Baixar o dataset do Roboflow e organizar as pastas necessárias.\n",
    "3. **Ajuste do Arquivo YAML**: Configurar o arquivo YAML com os caminhos corretos e parâmetros de detecção.\n",
    "4. **Divisão do Dataset**: Dividir o dataset em conjuntos de treino, validação e teste.\n",
    "5. **Treinamento do Modelo**: Treinar o modelo YOLOv8 com os dados preparados.\n",
    "\n",
    "## Requisitos\n",
    "\n",
    "- Python 3.8 ou superior\n",
    "- Bibliotecas: roboflow, sklearn, torch, ultralytics, yaml\n",
    "- Jupyter Notebook ou similar para execução dos blocos de código\n",
    "\n",
    "Cada seção a seguir detalha os passos necessários e inclui o código correspondente com comentários explicativos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3078ec-2499-4b14-85f5-7e1ae16ad9bc",
   "metadata": {},
   "source": [
    "## Etapa 1: Configuração do Ambiente\n",
    "\n",
    "Nesta etapa, carregamos as configurações do arquivo `settings.yaml` e preparamos o ambiente de trabalho. É importante garantir que o diretório base e o diretório de datasets estejam corretamente configurados antes de prosseguir.\n",
    "\n",
    "### Parâmetros Ajustáveis\n",
    "\n",
    "- `settings_file`: Caminho para o arquivo de configurações `settings.yaml`.\n",
    "- `datasets_dir`: Diretório onde os datasets serão armazenados.\n",
    "\n",
    "### Variáveis para Download do Dataset\n",
    "\n",
    "- `api_key`: Chave da API do Roboflow.\n",
    "- `workspace_name`: Nome do workspace no Roboflow.\n",
    "- `project_name`: Nome do projeto no Roboflow.\n",
    "- `version_number`: Número da versão do dataset.\n",
    "- `download_format`: Formato desejado para download.\n",
    "\n",
    "### Código de Configuração do Ambiente\n",
    "\n",
    "Este bloco de código faz o carregamento das configurações e prepara o ambiente de trabalho. Ele define variáveis importantes para o download do dataset e ajusta a estrutura de diretórios conforme necessário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd05b459-560a-4635-88e6-35d0099ab123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etapa 1: Configuração do Ambiente\n",
    "# Esta etapa carrega as configurações do arquivo settings.yaml e garante que a estrutura de diretórios necessária esteja presente.\n",
    "# Espera-se que as configurações sejam carregadas corretamente e que os diretórios base e de datasets estejam configurados.\n",
    "\n",
    "import os\n",
    "import yaml\n",
    "import subprocess\n",
    "\n",
    "# Função para carregar configurações do settings.yaml\n",
    "def load_settings():\n",
    "    # Expande o caminho para o diretório do usuário\n",
    "    user_home_dir = os.path.expanduser(\"~\")\n",
    "    # Define o caminho do arquivo settings.yaml no diretório padrão do Ultralytics\n",
    "    settings_file = os.path.join(user_home_dir, \"Library\", \"Application Support\", \"Ultralytics\", \"settings.yaml\")\n",
    "\n",
    "    try:\n",
    "        # Tenta abrir e carregar o arquivo settings.yaml\n",
    "        with open(settings_file, 'r') as file:\n",
    "            settings = yaml.safe_load(file)\n",
    "        print(\"Configurações carregadas com sucesso.\")\n",
    "        return settings\n",
    "    except FileNotFoundError:\n",
    "        # Caso o arquivo não seja encontrado, usa valores padrão\n",
    "        print(f\"Arquivo {settings_file} não encontrado. Usando valores padrão.\")\n",
    "        return {\n",
    "            'datasets_dir': 'datasets',\n",
    "            'weights_dir': 'weights',\n",
    "            'runs_dir': 'runs'\n",
    "        }\n",
    "    except Exception as e:\n",
    "        # Caso ocorra outro tipo de erro ao carregar o arquivo, usa valores padrão\n",
    "        print(f\"Erro ao carregar configurações: {e}\")\n",
    "        return {\n",
    "            'datasets_dir': 'datasets',\n",
    "            'weights_dir': 'weights',\n",
    "            'runs_dir': 'runs'\n",
    "        }\n",
    "\n",
    "# Carregar configurações a partir do arquivo settings.yaml\n",
    "settings = load_settings()\n",
    "\n",
    "# Obter o diretório de datasets a partir das configurações carregadas\n",
    "datasets_dir = settings.get('datasets_dir', 'datasets')\n",
    "# Definir o diretório base como o diretório pai do diretório de datasets\n",
    "base_dir = os.path.dirname(datasets_dir)\n",
    "\n",
    "# Variáveis para download do dataset\n",
    "api_key = \"caWwvxqugMKTqbXr3PBz\"       # Chave da API do Roboflow\n",
    "workspace_name = \"alex-novaes\"         # Nome do workspace no Roboflow\n",
    "project_name = \"granito-3nbcw\"         # Nome do projeto no Roboflow\n",
    "version_number = 1                     # Número da versão do dataset\n",
    "download_format = \"yolov8\"             # Formato desejado para download\n",
    "\n",
    "# Exibir os diretórios base e de datasets\n",
    "print(f\"Diretório base: {base_dir}\")\n",
    "print(f\"Diretório de datasets: {datasets_dir}\")\n",
    "\n",
    "# Função para garantir que o diretório base está correto e criar estrutura se necessário\n",
    "def setup_environment(base_dir, datasets_dir):\n",
    "    # Verifica e cria o diretório base, se necessário\n",
    "    if not os.path.exists(base_dir):\n",
    "        os.makedirs(base_dir)\n",
    "        print(f\"Diretório base criado: {base_dir}\")\n",
    "\n",
    "    # Verifica e cria o diretório de datasets, se necessário\n",
    "    if not os.path.exists(datasets_dir):\n",
    "        os.makedirs(datasets_dir)\n",
    "        print(f\"Diretório de datasets criado: {datasets_dir}\")\n",
    "\n",
    "    # Muda para o diretório base\n",
    "    os.chdir(base_dir)\n",
    "    print(f\"Diretório de trabalho alterado para: {base_dir}\")\n",
    "\n",
    "# Configura o ambiente\n",
    "setup_environment(base_dir, datasets_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70043948-79ee-4efb-ab1c-74da8f929780",
   "metadata": {},
   "source": [
    "## Etapa 2: Download do Dataset\n",
    "\n",
    "Nesta etapa, fazemos o download do dataset do Roboflow e organizamos as pastas necessárias. Se uma pasta com o mesmo nome já existir, ela será renomeada com a extensão \"-bkp\" para evitar conflitos.\n",
    "\n",
    "### Parâmetros Ajustáveis\n",
    "\n",
    "- `api_key`: Chave da API do Roboflow.\n",
    "- `workspace_name`: Nome do workspace no Roboflow.\n",
    "- `project_name`: Nome do projeto no Roboflow.\n",
    "- `version_number`: Número da versão do dataset.\n",
    "- `download_format`: Formato desejado para download.\n",
    "- `base_dir`: Diretório base onde o dataset será armazenado.\n",
    "\n",
    "### Código para Download do Dataset\n",
    "\n",
    "Este bloco de código realiza o download do dataset do Roboflow e garante que a estrutura de diretórios esteja correta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f57667-b650-48e8-82e1-85a7dc4f9461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etapa 2: Download do Dataset\n",
    "# Esta etapa baixa o dataset do Roboflow e o prepara para uso.\n",
    "\n",
    "from roboflow import Roboflow\n",
    "import shutil\n",
    "\n",
    "# Função para baixar o dataset do Roboflow\n",
    "def download_dataset(api_key, workspace_name, project_name, version_number, download_format, base_dir):\n",
    "    try:\n",
    "        # Configuração e autenticação com a API do Roboflow\n",
    "        rf = Roboflow(api_key=api_key)\n",
    "        project = rf.workspace(workspace_name).project(project_name)\n",
    "        version = project.version(version_number)\n",
    "\n",
    "        # Criação do diretório base se não existir\n",
    "        if not os.path.exists(base_dir):\n",
    "            os.makedirs(base_dir)\n",
    "\n",
    "        # Verificação e renomeação da pasta existente\n",
    "        dataset_location = os.path.join(base_dir, project_name)\n",
    "        if os.path.exists(dataset_location):\n",
    "            backup_location = dataset_location + \"-bkp\"\n",
    "            i = 1\n",
    "            while os.path.exists(backup_location):\n",
    "                backup_location = f\"{dataset_location}-bkp-{i}\"\n",
    "                i += 1\n",
    "            shutil.move(dataset_location, backup_location)\n",
    "            print(f\"Diretório existente renomeado para: {backup_location}\")\n",
    "\n",
    "        # Download do dataset no formato especificado\n",
    "        dataset = version.download(download_format)\n",
    "\n",
    "        # Move o dataset baixado para o diretório desejado\n",
    "        shutil.move(dataset.location, dataset_location)\n",
    "        print(\"Dataset {} versão {} baixado com sucesso no formato {}.\".format(project_name, version_number, download_format))\n",
    "        return dataset_location\n",
    "    except Exception as e:\n",
    "        import sys\n",
    "        sys.stderr.write(f\"Erro ao baixar o dataset: {e}\\n\")\n",
    "        return None\n",
    "\n",
    "# Executa o download do dataset\n",
    "dataset_dir = download_dataset(api_key, workspace_name, project_name, version_number, download_format, datasets_dir)\n",
    "\n",
    "if dataset_dir:\n",
    "    print(f\"Dataset baixado e salvo em: {dataset_dir}\")\n",
    "else:\n",
    "    print(\"Falha ao baixar o dataset.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51a396e-a944-4141-8795-4c472e25cea1",
   "metadata": {},
   "source": [
    "## Etapa 3: Ajuste do Arquivo YAML\n",
    "\n",
    "Nesta etapa, ajustamos o arquivo YAML com os caminhos corretos e parâmetros de detecção. Isso garante que o YOLOv8 possa encontrar os dados corretamente durante o treinamento.\n",
    "\n",
    "### Parâmetros Ajustáveis\n",
    "\n",
    "- `data_yaml_path`: Caminho para o arquivo YAML do dataset.\n",
    "- `conf_thres`: Limiar de confiança para detecção.\n",
    "- `iou_thres`: Limiar de IOU para Non-Maximum Suppression.\n",
    "\n",
    "### Código para Ajuste do Arquivo YAML\n",
    "\n",
    "Este bloco de código ajusta o arquivo YAML com os caminhos e parâmetros apropriados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d06d391-851d-4e78-9eff-b2397a925e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bloco 4 - Ajuste dos Rótulos\n",
    "# Este bloco ajusta os arquivos de rótulo para remover a classe \"fanado\" e reindexar as outras classes.\n",
    "\n",
    "import os\n",
    "\n",
    "# Caminho para os diretórios de labels (todas as imagens baixadas)\n",
    "label_dirs = [\n",
    "    os.path.join(dataset_dir, \"train\", \"labels\"),\n",
    "    os.path.join(dataset_dir, \"valid\", \"labels\"),\n",
    "    os.path.join(dataset_dir, \"test\", \"labels\")\n",
    "]\n",
    "\n",
    "# Função para ajustar os arquivos de rótulo\n",
    "def adjust_labels(label_dirs):\n",
    "    try:\n",
    "        for label_dir in label_dirs:\n",
    "            if os.path.exists(label_dir):\n",
    "                for label_file in os.listdir(label_dir):\n",
    "                    if label_file.endswith('.txt'):\n",
    "                        label_path = os.path.join(label_dir, label_file)\n",
    "                        with open(label_path, 'r') as file:\n",
    "                            lines = file.readlines()\n",
    "\n",
    "                        new_lines = []\n",
    "                        for line in lines:\n",
    "                            parts = line.strip().split()\n",
    "                            class_id = int(parts[0])\n",
    "                            if class_id == 3:  # Classe 'fanado' que queremos remover\n",
    "                                continue\n",
    "                            elif class_id > 3:  # Reindexando classes\n",
    "                                parts[0] = str(class_id - 1)\n",
    "                            new_lines.append(' '.join(parts))\n",
    "\n",
    "                        with open(label_path, 'w') as file:\n",
    "                            file.write('\\n'.join(new_lines) + '\\n')\n",
    "                print(f\"Arquivos de rótulo ajustados com sucesso em {label_dir}.\")\n",
    "            else:\n",
    "                print(f\"Diretório {label_dir} não encontrado.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao ajustar os arquivos de rótulo: {e}\")\n",
    "\n",
    "# Ajustar os arquivos de rótulo\n",
    "adjust_labels(label_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68ee760-d59c-44fc-804d-016822083e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etapa 3: Definição de Parâmetros Ajustáveis\n",
    "# Esta etapa define os parâmetros que podem ser ajustados pelo operador para a configuração do dataset e do modelo de detecção.\n",
    "# Espera-se que esses parâmetros possam ser modificados facilmente conforme necessário.\n",
    "\n",
    "import os\n",
    "\n",
    "# Parâmetros ajustáveis pelo operador\n",
    "# Caminho para o arquivo data.yaml no diretório do dataset baixado\n",
    "data_yaml_path = os.path.join(dataset_dir, \"data.yaml\")\n",
    "\n",
    "# Parâmetros de detecção\n",
    "conf_thres = 0.3  # Limiar de confiança para detecção\n",
    "iou_thres = 0.5   # Limiar de IOU para Non-Maximum Suppression\n",
    "\n",
    "# Exibindo os parâmetros configurados para verificação\n",
    "print(f\"Caminho para o arquivo data.yaml: {data_yaml_path}\")\n",
    "print(f\"Limiar de confiança para detecção (conf_thres): {conf_thres}\")\n",
    "print(f\"Limiar de IOU para Non-Maximum Suppression (iou_thres): {iou_thres}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4213af3-2d7d-41da-9452-39439dfb229e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bloco 5 - Ajuste do Arquivo YAML\n",
    "# Este bloco ajusta o arquivo YAML para refletir as mudanças na estrutura das classes.\n",
    "\n",
    "def adjust_yaml_file(data_yaml_path, datasets_dir, project_name, conf_thres, iou_thres):\n",
    "    try:\n",
    "        data = {\n",
    "            'path': os.path.join(\"..\", datasets_dir, project_name, 'train'),\n",
    "            'train': 'train',\n",
    "            'val': 'valid',\n",
    "            'test': 'test',\n",
    "            'names': {\n",
    "                0: 'chapa',\n",
    "                1: 'furo',\n",
    "                2: 'veio'\n",
    "            },\n",
    "            'nc': 3,\n",
    "            'detection': {\n",
    "                'conf_thres': conf_thres,\n",
    "                'iou_thres': iou_thres\n",
    "            },\n",
    "            'roboflow': {\n",
    "                'license': 'Public Domain',\n",
    "                'project': 'granito-3nbcw',\n",
    "                'url': 'https://universe.roboflow.com/alex-novaes/granito-3nbcw/dataset/1',\n",
    "                'version': 1,\n",
    "                'workspace': 'alex-novaes'\n",
    "            }\n",
    "        }\n",
    "\n",
    "        yaml_content = f\"\"\"\n",
    "# Configuração do Dataset GRANITO para Treinamento com YOLOv8\n",
    "# Este arquivo YAML configura o acesso e uso do dataset GRANITO para treinamento, validação e teste de um modelo YOLOv8.\n",
    "# A estrutura do diretório assume que as imagens estão organizadas dentro do diretório '{project_name}' em '{datasets_dir}'.\n",
    "\n",
    "# Estrutura de Diretórios Esperada:\n",
    "# ┌─ {os.path.basename(datasets_dir)}\n",
    "# │  └─ {project_name}\n",
    "# │     ├─ imagens\n",
    "# │     ├─ train\n",
    "# │     ├─ valid\n",
    "# │     └─ test\n",
    "\n",
    "# Caminhos para conjuntos de dados\n",
    "path: {data['path']}\n",
    "train: {data['train']}\n",
    "val: {data['val']}\n",
    "test: {data['test']}\n",
    "\n",
    "# Definição das Classes de Objetos\n",
    "names:\n",
    "  0: {data['names'][0]}\n",
    "  1: {data['names'][1]}\n",
    "  2: {data['names'][2]}\n",
    "\n",
    "nc: {data['nc']}  # Número de classes\n",
    "\n",
    "detection:\n",
    "  conf_thres: {data['detection']['conf_thres']}\n",
    "  iou_thres: {data['detection']['iou_thres']}\n",
    "\n",
    "roboflow:\n",
    "  license: {data['roboflow']['license']}\n",
    "  project: {data['roboflow']['project']}\n",
    "  url: {data['roboflow']['url']}\n",
    "  version: {data['roboflow']['version']}\n",
    "  workspace: {data['roboflow']['workspace']}\n",
    "\"\"\"\n",
    "\n",
    "        with open(data_yaml_path, 'w') as file:\n",
    "            file.write(yaml_content)\n",
    "\n",
    "        print(f\"Arquivo {data_yaml_path} ajustado com sucesso.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao ajustar o arquivo {data_yaml_path}: {e}\")\n",
    "\n",
    "# Ajustar o arquivo YAML com base nas configurações\n",
    "adjust_yaml_file(data_yaml_path, datasets_dir, project_name, conf_thres, iou_thres)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf16c09f-340d-47e9-ba73-7480a068077b",
   "metadata": {},
   "source": [
    "## Etapa 4: Divisão do Dataset\n",
    "\n",
    "Dividimos o dataset em conjuntos de treino, validação e teste. Esta etapa é crucial para garantir que o modelo seja treinado, validado e testado de forma eficiente e correta.\n",
    "\n",
    "### Parâmetros Ajustáveis\n",
    "\n",
    "- **data_dir**: Caminho para o diretório de dados.\n",
    "- **subsets**: Subconjuntos de dados (train, valid, test).\n",
    "- **test_size**: Percentual de dados para validação e teste. Este parâmetro define a proporção do dataset total que será usada para validação e teste. No nosso caso, usamos 0.2, o que significa que 20% do dataset será dividido entre validação e teste.\n",
    "  - **Motivo da escolha**: 20% é um valor comum que oferece um bom equilíbrio entre o tamanho dos conjuntos de treino e validação/teste, garantindo dados suficientes para ambos.\n",
    "  - **Opções**: Pode variar entre 0.1 e 0.3, dependendo do tamanho do dataset e da necessidade específica do projeto. Valores menores (ex: 0.1) são usados quando o dataset é muito grande, enquanto valores maiores (ex: 0.3) são usados quando o dataset é menor e é importante ter mais dados para validação e teste.\n",
    "- **val_size**: Percentual de dados de validação dentro do conjunto val/test. Este parâmetro define a proporção de dados no conjunto val/test que será usada para validação. No nosso caso, usamos 0.5, o que significa que metade dos dados de val/test será usada para validação.\n",
    "  - **Motivo da escolha**: 50% é uma escolha equilibrada, garantindo uma divisão igual entre validação e teste.\n",
    "  - **Opções**: Pode variar entre 0.3 e 0.7, dependendo da necessidade de dados de validação em relação aos dados de teste.\n",
    "- **random_state**: Seed para garantir a reprodutibilidade. Este parâmetro garante que a divisão dos dados seja a mesma a cada execução do código, permitindo a replicabilidade dos experimentos.\n",
    "  - **Motivo da escolha**: Usar um seed fixo (42) é uma prática comum que facilita a reprodutibilidade e comparação de resultados.\n",
    "  - **Opções**: Pode ser qualquer número inteiro. A escolha do número específico (42) é arbitrária, mas deve ser consistente entre as execuções para garantir a reprodutibilidade.\n",
    "\n",
    "### Código para Divisão do Dataset\n",
    "\n",
    "Este bloco de código realiza a divisão do dataset e organiza as pastas necessárias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c68b81-f4c4-4afa-afa9-2504575b10b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etapa 4: Divisão do Dataset\n",
    "# Esta etapa configura os parâmetros e prepara a divisão do dataset em conjuntos de treinamento, validação e teste.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# Diretório onde as imagens e labels estão localizadas\n",
    "data_dir = os.path.join(dataset_dir, \"train\")\n",
    "\n",
    "# Subconjuntos de dados\n",
    "subsets = ['train', 'valid', 'test']\n",
    "\n",
    "# Parâmetros de divisão dos dados\n",
    "test_size = 0.2      # Percentual de dados para validação e teste\n",
    "val_size = 0.5       # Percentual de dados de validação dentro do conjunto val/test\n",
    "random_state = 42    # Seed para garantir a reproducibilidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf203c8-9142-4742-8697-c61218f15b96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Etapa 4.1: Execução da Divisão do Dataset\n",
    "# Esta etapa divide o dataset em conjuntos de treinamento, validação e teste, e copia os arquivos para as respectivas pastas.\n",
    "\n",
    "# Cria os subdiretórios para imagens e labels dentro de train, valid e test\n",
    "for subset in subsets:\n",
    "    os.makedirs(os.path.join(data_dir, subset, 'images'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(data_dir, subset, 'labels'), exist_ok=True)\n",
    "\n",
    "try:\n",
    "    # Caminhos para as pastas de imagens e labels originais\n",
    "    image_dir = os.path.join(data_dir, \"images\")\n",
    "    label_dir = os.path.join(data_dir, \"labels\")\n",
    "    \n",
    "    # Listagem das imagens e labels\n",
    "    all_images = [f for f in os.listdir(image_dir) if f.endswith('.jpg')]\n",
    "    all_labels = [f.replace('.jpg', '.txt') for f in all_images]\n",
    "\n",
    "    # Divisão das imagens e labels em conjuntos de treino, validação e teste\n",
    "    train_images, val_test_images = train_test_split(all_images, test_size=test_size, random_state=random_state)\n",
    "    train_labels, val_test_labels = train_test_split(all_labels, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    val_images, test_images = train_test_split(val_test_images, test_size=val_size, random_state=random_state)\n",
    "    val_labels, test_labels = train_test_split(val_test_labels, test_size=val_size, random_state=random_state)\n",
    "\n",
    "    # Função para copiar arquivos para os diretórios correspondentes\n",
    "    def copy_files(images, labels, subset):\n",
    "        img_dir = os.path.join(data_dir, subset, 'images')\n",
    "        lbl_dir = os.path.join(data_dir, subset, 'labels')\n",
    "        for img, lbl in zip(images, labels):\n",
    "            shutil.copy(os.path.join(image_dir, img), img_dir)\n",
    "            shutil.copy(os.path.join(label_dir, lbl), lbl_dir)\n",
    "            print(f\"Arquivo {img} e seu label {lbl} copiados para {subset}\")\n",
    "\n",
    "    # Copiando os arquivos para os diretórios apropriados\n",
    "    copy_files(train_images, train_labels, 'train')\n",
    "    copy_files(val_images, val_labels, 'valid')\n",
    "    copy_files(test_images, test_labels, 'test')\n",
    "\n",
    "except Exception as e:\n",
    "    # Tratamento de exceções durante o processo de divisão\n",
    "    print(f\"Erro durante o processamento: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5961d96-b832-4af0-93f1-64d766d382a4",
   "metadata": {},
   "source": [
    "## Etapa 5: Treinamento do Modelo YOLOv8\n",
    "\n",
    "Nesta etapa, treinamos o modelo YOLOv8 usando os dados preparados nas etapas anteriores. Os parâmetros de treinamento são configurados para garantir um equilíbrio entre precisão e eficiência.\n",
    "\n",
    "### Parâmetros Ajustáveis\n",
    "\n",
    "- **data**: Caminho para o arquivo YAML que contém as configurações do dataset.\n",
    "  - **Motivo da escolha**: Necessário para o treinamento do modelo com as configurações e caminhos corretos para os dados.\n",
    "  - **Opções**: Caminho para qualquer arquivo YAML configurado corretamente.\n",
    "\n",
    "- **epochs**: Número de épocas de treinamento.\n",
    "  - **Motivo da escolha**: O valor de 10 é escolhido para um equilíbrio entre tempo de treinamento e qualidade do modelo. Mais épocas podem melhorar a precisão, mas aumentam o tempo de treinamento.\n",
    "  - **Opções**: Qualquer valor inteiro. Valores comuns são entre 10 e 100, dependendo dos recursos computacionais e do tempo disponível.\n",
    "\n",
    "- **imgsz**: Tamanho das imagens de entrada.\n",
    "  - **Motivo da escolha**: O valor de 640 é um bom compromisso entre qualidade da imagem e eficiência computacional.\n",
    "  - **Opções**: Comuns são 320, 416, 512, 640, etc. Tamanhos menores aumentam a velocidade, mas podem reduzir a precisão.\n",
    "\n",
    "- **batch**: Tamanho do lote de treinamento.\n",
    "  - **Motivo da escolha**: O valor de 16 é uma escolha comum que funciona bem na maioria dos sistemas sem esgotar a memória.\n",
    "  - **Opções**: Qualquer valor inteiro. Comuns são 8, 16, 32, 64. Depende da capacidade de memória da GPU.\n",
    "\n",
    "- **workers**: Número de workers.\n",
    "  - **Motivo da escolha**: O valor de 8 permite um bom balanceamento entre carga de CPU e velocidade de processamento.\n",
    "  - **Opções**: Qualquer valor inteiro. Comuns são entre 4 e 16, dependendo do número de núcleos da CPU.\n",
    "\n",
    "- **optimizer**: Otimizador.\n",
    "  - **Motivo da escolha**: A escolha de 'auto' permite ao sistema selecionar o melhor otimizador baseado no hardware e configuração.\n",
    "  - **Opções**: 'AdamW','SGD', 'Adam', 'RMSprop', 'auto'. A escolha depende do tipo de modelo e dados.\n",
    "\n",
    "- **verbose**: Modo verboso.\n",
    "  - **Motivo da escolha**: Ativar o modo verboso (`True`) ajuda a monitorar o progresso do treinamento e a identificar problemas rapidamente.\n",
    "  - **Opções**: `True` ou `False`. `True` para debug e monitoramento detalhado, `False` para execução silenciosa.\n",
    "\n",
    "- **device**: Tipo de dispositivo.\n",
    "  - **Motivo da escolha**: Definido automaticamente (`mps` se disponível, senão `cpu`), permite ao treinamento usar o melhor hardware disponível.\n",
    "  - **Opções**: 'cpu', 'cuda', 'mps'. A escolha depende do hardware disponível.\n",
    "  \n",
    "### Código para Treinamento do Modelo\n",
    "\n",
    "Este bloco de código realiza o treinamento do modelo YOLOv8 utilizando os parâmetros ajustados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7aa61d-8490-4c3c-a039-e8a1ccad9b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etapa 5: Configuração dos Parâmetros de Treinamento\n",
    "# Esta etapa configura os parâmetros necessários para o treinamento do modelo YOLOv8.\n",
    "\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import subprocess\n",
    "\n",
    "# Caminho para o arquivo de pesos do modelo YOLOv8\n",
    "model_path = \"runs/detect/train7/weights/best.pt\"\n",
    "\n",
    "# Caminho para o arquivo YAML que contém as configurações do dataset\n",
    "data_path = os.path.join(dataset_dir, \"data.yaml\")\n",
    "\n",
    "# Número de épocas de treinamento\n",
    "epochs = 10\n",
    "\n",
    "# Tamanho das imagens de entrada\n",
    "img_size = 640\n",
    "\n",
    "# Diretório para logs do TensorBoard, obtido das configurações carregadas\n",
    "log_dir = settings.get('runs_dir', 'runs')\n",
    "\n",
    "# Configuração do dispositivo de treinamento (usa 'mps' se disponível, senão 'cpu')\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "\n",
    "# Configuração dos parâmetros do treinamento\n",
    "batch_size = 16     # Tamanho do lote de treinamento\n",
    "workers = 8         # Número de workers\n",
    "optimizer = 'auto'  # Otimizador\n",
    "verbose = True      # Modo verboso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2075316a-e916-4238-a407-35d0ade59b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etapa 5.1: Execução do Treinamento do Modelo\n",
    "# Esta etapa executa o treinamento do modelo YOLOv8 com os parâmetros configurados anteriormente.\n",
    "\n",
    "# Exibir o dispositivo de treinamento\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Carregar o modelo YOLOv8\n",
    "model = YOLO(model_path)\n",
    "\n",
    "# Enviar o modelo para o dispositivo especificado (MPS ou CPU)\n",
    "model.to(device)\n",
    "\n",
    "# Verificar e criar o diretório de logs do TensorBoard, se necessário\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "# Iniciar o TensorBoard apontando para o diretório de logs\n",
    "subprocess.Popen([\"tensorboard\", \"--logdir\", log_dir])\n",
    "\n",
    "# Executar o treinamento do modelo com os parâmetros configurados\n",
    "results = model.train(\n",
    "    data=data_path,     # Caminho para o arquivo YAML que contém as configurações do dataset\n",
    "    epochs=epochs,      # Número de épocas de treinamento\n",
    "    imgsz=img_size,     # Tamanho das imagens de entrada\n",
    "    batch=batch_size,   # Tamanho do lote de treinamento\n",
    "    workers=workers,    # Número de workers\n",
    "    optimizer=optimizer,# Otimizador\n",
    "    verbose=verbose,    # Modo verboso\n",
    "    device=device.type  # Tipo de dispositivo como uma string\n",
    ")\n",
    "\n",
    "# Salvar o modelo treinado no diretório do dataset\n",
    "model.save(os.path.join(dataset_dir, \"model.pt\"))\n",
    "\n",
    "# Imprimir os resultados do treinamento\n",
    "print(\"Training completed. Results:\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e61248-2020-42ce-b0c3-6d9c49979782",
   "metadata": {},
   "source": [
    "## Considerações Finais\n",
    "\n",
    "Este projeto foi desenvolvido com o objetivo de ser replicável e fácil de entender. Cada etapa foi detalhadamente documentada para garantir que futuros usuários possam seguir o processo sem dificuldades. Se houver dúvidas ou sugestões, sinta-se à vontade para entrar em contato comigo ou com meu orientador."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
