{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f75e2d9-11d3-4092-a5ff-45aa84decd84",
   "metadata": {},
   "source": [
    "# **Projeto de Detecção de Defeitos em Chapas de Granito com YOLOv8**\n",
    "## **Dissertação de Mestrado**\n",
    "\n",
    "**Autor**: Alexsander Alves Novaes\n",
    "\n",
    "**Orientador**: Prof. Dr. Daniel Cruz Cavalieri\n",
    "\n",
    "**Instituição**: IFES\n",
    "\n",
    "**Data**: Jul/2024 \n",
    "\n",
    "## Contexto\n",
    "\n",
    "Este projeto visa a detecção automática de defeitos em chapas de granito utilizando o modelo YOLOv8. O objetivo é desenvolver um pipeline completo e replicável para identificar diferentes tipos de defeitos em imagens de chapas de granito. Este documento é parte integrante da dissertação de mestrado e contém todos os passos necessários para executar e replicar o projeto, desde a configuração do ambiente até o treinamento do modelo.\n",
    "\n",
    "## Objetivos\n",
    "\n",
    "1. **Configuração do Ambiente**: Carregar configurações e preparar o ambiente de trabalho.\n",
    "2. **Download do Dataset**: Baixar o dataset do Roboflow e organizar as pastas necessárias.\n",
    "3. **Ajuste do Arquivo YAML**: Configurar o arquivo YAML com os caminhos corretos e parâmetros de detecção.\n",
    "4. **Divisão do Dataset**: Dividir o dataset em conjuntos de treino, validação e teste.\n",
    "5. **Treinamento do Modelo**: Treinar o modelo YOLOv8 com os dados preparados.\n",
    "\n",
    "## Requisitos\n",
    "\n",
    "- Python 3.8 ou superior\n",
    "- Bibliotecas presentes no arquivo requirements.txt\n",
    "- Jupyter Notebook ou similar para execução dos blocos de código\n",
    "\n",
    "### Lista de Bibliotecas e Versões\n",
    "\n",
    "```plaintext\n",
    "ipykernel==6.29.5\n",
    "jupyter==1.0.0\n",
    "jupyterlab==4.2.4\n",
    "matplotlib==3.9.1\n",
    "opencv-python==4.10.0.84\n",
    "roboflow==1.1.36\n",
    "scikit-learn==1.5.1\n",
    "tabulate==0.9.0\n",
    "torch==2.3.1\n",
    "ultralytics==8.2.60\n",
    "PyYAML==6.0.1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7439bc2b-2b96-4a9a-a3d3-7afd7dadb415",
   "metadata": {},
   "source": [
    "## **Divisão do Código em Etapas**\n",
    "\n",
    "Para assegurar a replicabilidade e a compreensão detalhada do projeto de detecção de defeitos em chapas de granito utilizando o modelo YOLOv8, o desenvolvimento foi estruturado em várias etapas sequenciais. Cada etapa desempenha um papel crucial no preparo do ambiente, na manipulação dos dados, na configuração do modelo e na análise dos resultados. A seguir, apresento uma descrição detalhada de cada etapa do projeto:\n",
    "\n",
    "### **Etapa 1:** Configuração do Ambiente\n",
    "Nesta etapa inicial, o objetivo é garantir que o ambiente de trabalho esteja corretamente configurado. Carregam-se as configurações a partir do arquivo `settings.yaml`, que contém parâmetros essenciais como os diretórios de datasets, pesos do modelo e resultados das detecções. Verificam-se e criam-se as estruturas de diretórios necessárias para armazenar os dados e resultados. A correta configuração do ambiente é fundamental para o sucesso das etapas subsequentes, pois reduz a probabilidade de erros decorrentes de problemas de configuração e assegura que todas as operações sejam realizadas em um ambiente organizado e consistente.\n",
    "\n",
    "### **Etapa 2:** Download do Dataset\n",
    "Com o ambiente configurado, procede-se ao download do dataset. Utiliza-se a API do Roboflow para baixar o conjunto de dados específico necessário para o treinamento e teste do modelo. Esta etapa é crucial para garantir que se tenha acesso aos dados mais recentes e organizados no formato adequado para uso com o YOLOv8. O dataset inclui imagens de chapas de granito e seus respectivos rótulos de defeitos, que são essenciais para o treinamento do modelo de detecção. A obtenção de dados de alta qualidade e devidamente rotulados é fundamental para o desenvolvimento de um modelo robusto e preciso.\n",
    "\n",
    "### **Etapa 3:** Definição de Parâmetros Ajustáveis\n",
    "Nesta etapa, definem-se os parâmetros que podem ser ajustados pelo operador para personalizar a configuração do dataset e do modelo de detecção. Esses parâmetros incluem o limiar de confiança para detecção, os diretórios de entrada e saída, e outros parâmetros específicos do modelo YOLOv8. A flexibilidade na definição desses parâmetros permite a adaptação do modelo a diferentes conjuntos de dados e requisitos específicos, facilitando a experimentação e a otimização do modelo para obter os melhores resultados possíveis. A possibilidade de ajustar esses parâmetros sem modificar o código facilita a manutenção e a escalabilidade do projeto.\n",
    "\n",
    "### **Etapa 3.1:** Ajuste do Arquivo YAML\n",
    "O arquivo YAML do dataset é ajustado para refletir quaisquer mudanças na estrutura das classes. Este ajuste é necessário para garantir que o modelo YOLOv8 reconheça corretamente as classes de defeitos presentes nos dados. A atualização do arquivo YAML assegura a consistência entre os dados de treinamento e os parâmetros do modelo, garantindo que as detecções sejam precisas e que os rótulos sejam corretamente interpretados pelo modelo durante o treinamento e a inferência. A precisão na configuração do arquivo YAML é vital para a correta operação do modelo.\n",
    "\n",
    "### **Etapa 4:** Divisão do Dataset\n",
    "Para avaliar o desempenho do modelo de maneira robusta, é essencial dividir o dataset em conjuntos de treinamento, validação e teste. Nesta etapa, configuram-se os parâmetros para essa divisão, garantindo que os dados sejam distribuídos de maneira equilibrada e representativa. A divisão adequada dos dados é crucial para evitar overfitting e assegurar que o modelo generalize bem para novos dados. Um conjunto de treinamento bem balanceado é vital para o aprendizado do modelo, enquanto os conjuntos de validação e teste são usados para avaliar o desempenho do modelo em dados não vistos. A correta divisão do dataset é fundamental para a obtenção de um modelo robusto e confiável.\n",
    "\n",
    "### **Etapa 4.1:** Execução da Divisão do Dataset\n",
    "Nesta subetapa, executa-se a divisão do dataset configurada anteriormente. Os dados são organizados em pastas específicas para treinamento, validação e teste. Cada conjunto recebe suas respectivas imagens e rótulos, preparando o dataset para o processo de treinamento do modelo. Este processo envolve a cópia e organização dos arquivos em uma estrutura de diretórios que facilita o acesso e uso pelo modelo YOLOv8 durante o treinamento e avaliação. A organização eficiente dos dados é essencial para a correta execução das etapas de treinamento e validação.\n",
    "\n",
    "### **Etapa 5:** Configuração dos Parâmetros de Treinamento\n",
    "Finalmente, configuram-se os parâmetros necessários para o treinamento do modelo YOLOv8. Isso inclui a definição do número de épocas, o tamanho das imagens de entrada, o diretório para logs, entre outros. Esses parâmetros são fundamentais para controlar o processo de treinamento e otimização do modelo, garantindo que ele atinja a melhor performance possível na detecção de defeitos. A configuração cuidadosa desses parâmetros permite um treinamento eficiente e eficaz, maximizando a capacidade do modelo de detectar defeitos com alta precisão. A correta configuração dos parâmetros de treinamento é determinante para o sucesso do projeto.\n",
    "\n",
    "Cada uma dessas etapas foi detalhadamente planejada e documentada para garantir que qualquer pesquisador possa replicar e adaptar o projeto às suas necessidades específicas. A seguir, apresentamos o código correspondente a cada etapa do projeto, proporcionando uma visão prática e aplicada do processo descrito."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3078ec-2499-4b14-85f5-7e1ae16ad9bc",
   "metadata": {},
   "source": [
    "# **Execução dos códigos**\n",
    "\n",
    "## **Etapa 1:** Configuração do Ambiente\n",
    "\n",
    "Nesta etapa, carregamos as configurações do arquivo `settings.yaml` e preparamos o ambiente de trabalho. É importante garantir que o diretório base e o diretório de datasets estejam corretamente configurados antes de prosseguir.\n",
    "\n",
    "### **Parâmetros Ajustáveis**\n",
    "\n",
    "- **`settings_file`**: Caminho para o arquivo de configurações `settings.yaml`.\n",
    "- **`datasets_dir`**: Diretório onde os datasets serão armazenados.\n",
    "\n",
    "### **Variáveis para Download do Dataset**\n",
    "\n",
    "- **`api_key`**: Chave da API do Roboflow.\n",
    "- **`workspace_name`**: Nome do workspace no Roboflow.\n",
    "- **`project_name`**: Nome do projeto no Roboflow.\n",
    "- **`version_number`**: Número da versão do dataset.\n",
    "- **`download_format`**: Formato desejado para download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd05b459-560a-4635-88e6-35d0099ab123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etapa 1: Configuração do Ambiente\n",
    "# Esta etapa carrega as configurações do arquivo settings.yaml e garante que a estrutura de diretórios necessária esteja presente.\n",
    "# Espera-se que as configurações sejam carregadas corretamente e que os diretórios base e de datasets estejam configurados.\n",
    "\n",
    "import os\n",
    "import yaml\n",
    "import subprocess\n",
    "\n",
    "# Função para carregar configurações do settings.yaml\n",
    "def load_settings():\n",
    "    # Expande o caminho para o diretório do usuário\n",
    "    user_home_dir = os.path.expanduser(\"~\")\n",
    "    # Define o caminho do arquivo settings.yaml no diretório padrão do Ultralytics\n",
    "    settings_file = os.path.join(user_home_dir, \"Library\", \"Application Support\", \"Ultralytics\", \"settings.yaml\")\n",
    "\n",
    "    try:\n",
    "        # Tenta abrir e carregar o arquivo settings.yaml\n",
    "        with open(settings_file, 'r') as file:\n",
    "            settings = yaml.safe_load(file)\n",
    "        print(\"Configurações carregadas com sucesso.\")\n",
    "        return settings\n",
    "    except FileNotFoundError:\n",
    "        # Caso o arquivo não seja encontrado, usa valores padrão\n",
    "        print(f\"Arquivo {settings_file} não encontrado. Usando valores padrão.\")\n",
    "        return {\n",
    "            'datasets_dir': 'datasets',\n",
    "            'weights_dir': 'weights',\n",
    "            'runs_dir': 'runs'\n",
    "        }\n",
    "    except Exception as e:\n",
    "        # Caso ocorra outro tipo de erro ao carregar o arquivo, usa valores padrão\n",
    "        print(f\"Erro ao carregar configurações: {e}\")\n",
    "        return {\n",
    "            'datasets_dir': 'datasets',\n",
    "            'weights_dir': 'weights',\n",
    "            'runs_dir': 'runs'\n",
    "        }\n",
    "\n",
    "# Carregar configurações a partir do arquivo settings.yaml\n",
    "settings = load_settings()\n",
    "\n",
    "# Obter o diretório de datasets a partir das configurações carregadas\n",
    "datasets_dir = settings.get('datasets_dir', 'datasets')\n",
    "# Definir o diretório base como o diretório pai do diretório de datasets\n",
    "base_dir = os.path.dirname(datasets_dir)\n",
    "\n",
    "# Variáveis para download do dataset\n",
    "api_key = \"caWwvxqugMKTqbXr3PBz\"       # Chave da API do Roboflow\n",
    "workspace_name = \"alex-novaes\"         # Nome do workspace no Roboflow\n",
    "project_name = \"granito-3nbcw\"         # Nome do projeto no Roboflow\n",
    "version_number = 1                     # Número da versão do dataset\n",
    "download_format = \"yolov8\"             # Formato desejado para download\n",
    "\n",
    "# Exibir os diretórios base e de datasets\n",
    "print(f\"Diretório base: {base_dir}\")\n",
    "print(f\"Diretório de datasets: {datasets_dir}\")\n",
    "\n",
    "# Função para garantir que o diretório base está correto e criar estrutura se necessário\n",
    "def setup_environment(base_dir, datasets_dir):\n",
    "    # Verifica e cria o diretório base, se necessário\n",
    "    if not os.path.exists(base_dir):\n",
    "        os.makedirs(base_dir)\n",
    "        print(f\"Diretório base criado: {base_dir}\")\n",
    "\n",
    "    # Verifica e cria o diretório de datasets, se necessário\n",
    "    if not os.path.exists(datasets_dir):\n",
    "        os.makedirs(datasets_dir)\n",
    "        print(f\"Diretório de datasets criado: {datasets_dir}\")\n",
    "\n",
    "    # Muda para o diretório base\n",
    "    os.chdir(base_dir)\n",
    "    print(f\"Diretório de trabalho alterado para: {base_dir}\")\n",
    "\n",
    "# Configura o ambiente\n",
    "setup_environment(base_dir, datasets_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70043948-79ee-4efb-ab1c-74da8f929780",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## **Etapa 2:** Download do Dataset\n",
    "\n",
    "Nesta etapa, fazemos o download do dataset do Roboflow e organizamos as pastas necessárias. Se uma pasta com o mesmo nome já existir, ela será renomeada com a extensão \"-bkp\" para evitar conflitos.\n",
    "\n",
    "### Parâmetros Ajustáveis\n",
    "\n",
    "- **`api_key`**: Chave da API do Roboflow.\n",
    "- **`workspace_name`**: Nome do workspace no Roboflow.\n",
    "- **`project_name`**: Nome do projeto no Roboflow.\n",
    "- **`version_number`**: Número da versão do dataset.\n",
    "- **`download_format`**: Formato desejado para download.\n",
    "- **`base_dir`**: Diretório base onde o dataset será armazenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f57667-b650-48e8-82e1-85a7dc4f9461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etapa 2: Download do Dataset\n",
    "# Esta etapa baixa o dataset do Roboflow e o prepara para uso.\n",
    "\n",
    "from roboflow import Roboflow\n",
    "import shutil\n",
    "\n",
    "# Função para baixar o dataset do Roboflow\n",
    "def download_dataset(api_key, workspace_name, project_name, version_number, download_format, base_dir):\n",
    "    try:\n",
    "        # Configuração e autenticação com a API do Roboflow\n",
    "        rf = Roboflow(api_key=api_key)\n",
    "        project = rf.workspace(workspace_name).project(project_name)\n",
    "        version = project.version(version_number)\n",
    "\n",
    "        # Criação do diretório base se não existir\n",
    "        if not os.path.exists(base_dir):\n",
    "            os.makedirs(base_dir)\n",
    "\n",
    "        # Verificação e renomeação da pasta existente\n",
    "        dataset_location = os.path.join(base_dir, project_name)\n",
    "        if os.path.exists(dataset_location):\n",
    "            backup_location = dataset_location + \"-bkp\"\n",
    "            i = 1\n",
    "            while os.path.exists(backup_location):\n",
    "                backup_location = f\"{dataset_location}-bkp-{i}\"\n",
    "                i += 1\n",
    "            shutil.move(dataset_location, backup_location)\n",
    "            print(f\"Diretório existente renomeado para: {backup_location}\")\n",
    "\n",
    "        # Download do dataset no formato especificado\n",
    "        dataset = version.download(download_format)\n",
    "\n",
    "        # Move o dataset baixado para o diretório desejado\n",
    "        shutil.move(dataset.location, dataset_location)\n",
    "        print(\"Dataset {} versão {} baixado com sucesso no formato {}.\".format(project_name, version_number, download_format))\n",
    "        return dataset_location\n",
    "    except Exception as e:\n",
    "        import sys\n",
    "        sys.stderr.write(f\"Erro ao baixar o dataset: {e}\\n\")\n",
    "        return None\n",
    "\n",
    "# Executa o download do dataset\n",
    "dataset_dir = download_dataset(api_key, workspace_name, project_name, version_number, download_format, datasets_dir)\n",
    "\n",
    "if dataset_dir:\n",
    "    print(f\"Dataset baixado e salvo em: {dataset_dir}\")\n",
    "else:\n",
    "    print(\"Falha ao baixar o dataset.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51a396e-a944-4141-8795-4c472e25cea1",
   "metadata": {},
   "source": [
    "## **Etapa 3:** Ajuste do Arquivo YAML\n",
    "\n",
    "Nesta etapa, ajustamos o arquivo YAML com os caminhos corretos e parâmetros de detecção. Isso garante que o YOLOv8 possa encontrar os dados corretamente durante o treinamento.\n",
    "\n",
    "### Parâmetros Ajustáveis\n",
    "\n",
    "- **`data_yaml_path`**: Caminho para o arquivo YAML do dataset.\n",
    "- **`conf_thres`**: Limiar de confiança para detecção.\n",
    "- **`iou_thres`**: Limiar de IOU para Non-Maximum Suppression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68ee760-d59c-44fc-804d-016822083e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etapa 3: Definição de Parâmetros Ajustáveis\n",
    "# Esta etapa define os parâmetros que podem ser ajustados pelo operador para a configuração do dataset e do modelo de detecção.\n",
    "# Espera-se que esses parâmetros possam ser modificados facilmente conforme necessário.\n",
    "\n",
    "import os\n",
    "\n",
    "# Parâmetros ajustáveis pelo operador\n",
    "# Caminho para o arquivo data.yaml no diretório do dataset baixado\n",
    "data_yaml_path = os.path.join(dataset_dir, \"data.yaml\")\n",
    "\n",
    "# Parâmetros de detecção\n",
    "conf_thres = 0.3  # Limiar de confiança para detecção\n",
    "iou_thres = 0.5   # Limiar de IOU para Non-Maximum Suppression\n",
    "\n",
    "# Exibindo os parâmetros configurados para verificação\n",
    "print(f\"Caminho para o arquivo data.yaml: {data_yaml_path}\")\n",
    "print(f\"Limiar de confiança para detecção (conf_thres): {conf_thres}\")\n",
    "print(f\"Limiar de IOU para Non-Maximum Suppression (iou_thres): {iou_thres}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4213af3-2d7d-41da-9452-39439dfb229e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etapa 3.1: Ajuste do Arquivo YAML\n",
    "# Este bloco ajusta o arquivo YAML para refletir as mudanças na estrutura das classes.\n",
    "\n",
    "def adjust_yaml_file(data_yaml_path, datasets_dir, project_name, conf_thres, iou_thres):\n",
    "    try:\n",
    "        data = {\n",
    "            'path': os.path.join(\"..\", datasets_dir, project_name, 'train'),\n",
    "            'train': 'train',\n",
    "            'val': 'valid',\n",
    "            'test': 'test',\n",
    "            'names': {\n",
    "                0: 'chapa',\n",
    "                1: 'furo',\n",
    "                2: 'veio'\n",
    "            },\n",
    "            'nc': 3,\n",
    "            'detection': {\n",
    "                'conf_thres': conf_thres,\n",
    "                'iou_thres': iou_thres\n",
    "            },\n",
    "            'roboflow': {\n",
    "                'license': 'Public Domain',\n",
    "                'project': 'granito-3nbcw',\n",
    "                'url': 'https://universe.roboflow.com/alex-novaes/granito-3nbcw/dataset/1',\n",
    "                'version': 1,\n",
    "                'workspace': 'alex-novaes'\n",
    "            }\n",
    "        }\n",
    "\n",
    "        yaml_content = f\"\"\"\n",
    "# Configuração do Dataset GRANITO para Treinamento com YOLOv8\n",
    "# Este arquivo YAML configura o acesso e uso do dataset GRANITO para treinamento, validação e teste de um modelo YOLOv8.\n",
    "# A estrutura do diretório assume que as imagens estão organizadas dentro do diretório '{project_name}' em '{datasets_dir}'.\n",
    "\n",
    "# Estrutura de Diretórios Esperada:\n",
    "# ┌─ {os.path.basename(datasets_dir)}\n",
    "# │  └─ {project_name}\n",
    "# │     ├─ imagens\n",
    "# │     ├─ train\n",
    "# │     ├─ valid\n",
    "# │     └─ test\n",
    "\n",
    "# Caminhos para conjuntos de dados\n",
    "path: {data['path']}\n",
    "train: {data['train']}\n",
    "val: {data['val']}\n",
    "test: {data['test']}\n",
    "\n",
    "# Definição das Classes de Objetos\n",
    "names:\n",
    "  0: {data['names'][0]}\n",
    "  1: {data['names'][1]}\n",
    "  2: {data['names'][2]}\n",
    "\n",
    "nc: {data['nc']}  # Número de classes\n",
    "\n",
    "detection:\n",
    "  conf_thres: {data['detection']['conf_thres']}\n",
    "  iou_thres: {data['detection']['iou_thres']}\n",
    "\n",
    "roboflow:\n",
    "  license: {data['roboflow']['license']}\n",
    "  project: {data['roboflow']['project']}\n",
    "  url: {data['roboflow']['url']}\n",
    "  version: {data['roboflow']['version']}\n",
    "  workspace: {data['roboflow']['workspace']}\n",
    "\"\"\"\n",
    "\n",
    "        with open(data_yaml_path, 'w') as file:\n",
    "            file.write(yaml_content)\n",
    "\n",
    "        print(f\"Arquivo {data_yaml_path} ajustado com sucesso.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao ajustar o arquivo {data_yaml_path}: {e}\")\n",
    "\n",
    "# Ajustar o arquivo YAML com base nas configurações\n",
    "adjust_yaml_file(data_yaml_path, datasets_dir, project_name, conf_thres, iou_thres)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf16c09f-340d-47e9-ba73-7480a068077b",
   "metadata": {},
   "source": [
    "## **Etapa 4:** Divisão do Dataset\n",
    "\n",
    "Dividimos o dataset em conjuntos de treino, validação e teste. Esta etapa é crucial para garantir que o modelo seja treinado, validado e testado de forma eficiente e correta.\n",
    "\n",
    "### Parâmetros Ajustáveis\n",
    "\n",
    "- **`data_dir`**: Caminho para o diretório de dados.\n",
    "- **`subsets`**: Subconjuntos de dados (train, valid, test).\n",
    "- **`test_size`**: Percentual de dados para validação e teste. Este parâmetro define a proporção do dataset total que será usada para validação e teste. No nosso caso, usamos 0.2, o que significa que 20% do dataset será dividido entre validação e teste.\n",
    "  - **Motivo da escolha**: 20% é um valor comum que oferece um bom equilíbrio entre o tamanho dos conjuntos de treino e validação/teste, garantindo dados suficientes para ambos.\n",
    "  - **Opções**: Pode variar entre 0.1 e 0.3, dependendo do tamanho do dataset e da necessidade específica do projeto. Valores menores (ex: 0.1) são usados quando o dataset é muito grande, enquanto valores maiores (ex: 0.3) são usados quando o dataset é menor e é importante ter mais dados para validação e teste.\n",
    "- **`val_size`**: Percentual de dados de validação dentro do conjunto val/test. Este parâmetro define a proporção de dados no conjunto val/test que será usada para validação. No nosso caso, usamos 0.5, o que significa que metade dos dados de val/test será usada para validação.\n",
    "  - **Motivo da escolha**: 50% é uma escolha equilibrada, garantindo uma divisão igual entre validação e teste.\n",
    "  - **Opções**: Pode variar entre 0.3 e 0.7, dependendo da necessidade de dados de validação em relação aos dados de teste.\n",
    "- **`random_state`**: Seed para garantir a reprodutibilidade. Este parâmetro garante que a divisão dos dados seja a mesma a cada execução do código, permitindo a replicabilidade dos experimentos.\n",
    "  - **Motivo da escolha**: Usar um seed fixo (42) é uma prática comum que facilita a reprodutibilidade e comparação de resultados.\n",
    "  - **Opções**: Pode ser qualquer número inteiro. A escolha do número específico (42) é arbitrária, mas deve ser consistente entre as execuções para garantir a reprodutibilidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c68b81-f4c4-4afa-afa9-2504575b10b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etapa 4: Divisão do Dataset\n",
    "# Esta etapa configura os parâmetros e prepara a divisão do dataset em conjuntos de treinamento, validação e teste.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# Diretório onde as imagens e labels estão localizadas\n",
    "data_dir = os.path.join(dataset_dir, \"train\")\n",
    "\n",
    "# Subconjuntos de dados\n",
    "subsets = ['train', 'valid', 'test']\n",
    "\n",
    "# Parâmetros de divisão dos dados\n",
    "test_size = 0.2      # Percentual de dados para validação e teste\n",
    "val_size = 0.5       # Percentual de dados de validação dentro do conjunto val/test\n",
    "random_state = 42    # Seed para garantir a reproducibilidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf203c8-9142-4742-8697-c61218f15b96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Etapa 4.1: Execução da Divisão do Dataset\n",
    "# Esta etapa divide o dataset em conjuntos de treinamento, validação e teste, e copia os arquivos para as respectivas pastas.\n",
    "\n",
    "# Cria os subdiretórios para imagens e labels dentro de train, valid e test\n",
    "for subset in subsets:\n",
    "    os.makedirs(os.path.join(data_dir, subset, 'images'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(data_dir, subset, 'labels'), exist_ok=True)\n",
    "\n",
    "try:\n",
    "    # Caminhos para as pastas de imagens e labels originais\n",
    "    image_dir = os.path.join(data_dir, \"images\")\n",
    "    label_dir = os.path.join(data_dir, \"labels\")\n",
    "    \n",
    "    # Listagem das imagens e labels\n",
    "    all_images = [f for f in os.listdir(image_dir) if f.endswith('.jpg')]\n",
    "    all_labels = [f.replace('.jpg', '.txt') for f in all_images]\n",
    "\n",
    "    # Divisão das imagens e labels em conjuntos de treino, validação e teste\n",
    "    train_images, val_test_images = train_test_split(all_images, test_size=test_size, random_state=random_state)\n",
    "    train_labels, val_test_labels = train_test_split(all_labels, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    val_images, test_images = train_test_split(val_test_images, test_size=val_size, random_state=random_state)\n",
    "    val_labels, test_labels = train_test_split(val_test_labels, test_size=val_size, random_state=random_state)\n",
    "\n",
    "    # Função para copiar arquivos para os diretórios correspondentes\n",
    "    def copy_files(images, labels, subset):\n",
    "        img_dir = os.path.join(data_dir, subset, 'images')\n",
    "        lbl_dir = os.path.join(data_dir, subset, 'labels')\n",
    "        for img, lbl in zip(images, labels):\n",
    "            shutil.copy(os.path.join(image_dir, img), img_dir)\n",
    "            shutil.copy(os.path.join(label_dir, lbl), lbl_dir)\n",
    "            print(f\"Arquivo {img} e seu label {lbl} copiados para {subset}\")\n",
    "\n",
    "    # Copiando os arquivos para os diretórios apropriados\n",
    "    copy_files(train_images, train_labels, 'train')\n",
    "    copy_files(val_images, val_labels, 'valid')\n",
    "    copy_files(test_images, test_labels, 'test')\n",
    "\n",
    "except Exception as e:\n",
    "    # Tratamento de exceções durante o processo de divisão\n",
    "    print(f\"Erro durante o processamento: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5961d96-b832-4af0-93f1-64d766d382a4",
   "metadata": {},
   "source": [
    "## **Etapa 5:** Treinamento do Modelo YOLOv8\n",
    "\n",
    "Nesta etapa, treinamos o modelo YOLOv8 usando os dados preparados nas etapas anteriores. Os parâmetros de treinamento são configurados para garantir um equilíbrio entre precisão e eficiência.\n",
    "\n",
    "### Parâmetros Ajustáveis\n",
    "\n",
    "- **`data`**: Caminho para o arquivo YAML que contém as configurações do dataset.\n",
    "  - **Motivo da escolha**: Necessário para o treinamento do modelo com as configurações e caminhos corretos para os dados.\n",
    "  - **Opções**: Caminho para qualquer arquivo YAML configurado corretamente.\n",
    "\n",
    "- **`epochs`**: Número de épocas de treinamento.\n",
    "  - **Motivo da escolha**: O valor de 10 é escolhido para um equilíbrio entre tempo de treinamento e qualidade do modelo. Mais épocas podem melhorar a precisão, mas aumentam o tempo de treinamento.\n",
    "  - **Opções**: Qualquer valor inteiro. Valores comuns são entre 10 e 100, dependendo dos recursos computacionais e do tempo disponível.\n",
    "\n",
    "- **`imgsz`**: Tamanho das imagens de entrada.\n",
    "  - **Motivo da escolha**: O valor de 640 é um bom compromisso entre qualidade da imagem e eficiência computacional.\n",
    "  - **Opções**: Comuns são 320, 416, 512, 640, etc. Tamanhos menores aumentam a velocidade, mas podem reduzir a precisão.\n",
    "\n",
    "- **`batch`**: Tamanho do lote de treinamento.\n",
    "  - **Motivo da escolha**: O valor de 16 é uma escolha comum que funciona bem na maioria dos sistemas sem esgotar a memória.\n",
    "  - **Opções**: Qualquer valor inteiro. Comuns são 8, 16, 32, 64. Depende da capacidade de memória da GPU.\n",
    "\n",
    "- **`workers`**: Número de workers.\n",
    "  - **Motivo da escolha**: O valor de 8 permite um bom balanceamento entre carga de CPU e velocidade de processamento.\n",
    "  - **Opções**: Qualquer valor inteiro. Comuns são entre 4 e 16, dependendo do número de núcleos da CPU.\n",
    "\n",
    "- **`optimizer`**: Otimizador.\n",
    "  - **Motivo da escolha**: A escolha de 'auto' permite ao sistema selecionar o melhor otimizador baseado no hardware e configuração.\n",
    "  - **Opções**: 'AdamW','SGD', 'Adam', 'RMSprop', 'auto'. A escolha depende do tipo de modelo e dados.\n",
    "\n",
    "- **`verbose`**: Modo verboso.\n",
    "  - **Motivo da escolha**: Ativar o modo verboso (`True`) ajuda a monitorar o progresso do treinamento e a identificar problemas rapidamente.\n",
    "  - **Opções**: `True` ou `False`. `True` para debug e monitoramento detalhado, `False` para execução silenciosa.\n",
    "\n",
    "- **`device`**: Tipo de dispositivo.\n",
    "  - **Motivo da escolha**: Definido automaticamente (`mps` se disponível, senão `cpu`), permite ao treinamento usar o melhor hardware disponível.\n",
    "  - **Opções**: 'cpu', 'cuda', 'mps'. A escolha depende do hardware disponível.\n",
    "\n",
    "### **Explicação sobre Focal Loss**\n",
    "\n",
    "#### **O que é Focal Loss?**\n",
    "\n",
    "A Focal Loss é uma função de perda projetada para lidar com o problema do desequilíbrio de classes em tarefas de detecção de objetos. Foi introduzida por Tsung-Yi Lin et al. no artigo [\"Focal Loss for Dense Object Detection\"](https://arxiv.org/abs/1708.02002). A Focal Loss modifica a função de perda de Entropia Cruzada (Cross-Entropy Loss) tradicional, reduzindo a contribuição dos exemplos bem classificados e aumentando o foco em exemplos difíceis e mal classificados.\n",
    "\n",
    "#### **Fórmula da Focal Loss**\n",
    "\n",
    "### Explicação sobre Focal Loss\n",
    "\n",
    "#### O que é Focal Loss?\n",
    "\n",
    "A Focal Loss é uma função de perda projetada para lidar com o problema do desequilíbrio de classes em tarefas de detecção de objetos. Foi introduzida por Tsung-Yi Lin et al. no artigo [\"Focal Loss for Dense Object Detection\"](https://arxiv.org/abs/1708.02002). A Focal Loss modifica a função de perda de Entropia Cruzada (Cross-Entropy Loss) tradicional, reduzindo a contribuição dos exemplos bem classificados e aumentando o foco em exemplos difíceis e mal classificados.\n",
    "\n",
    "#### Fórmula da Focal Loss\n",
    "\n",
    "A Focal Loss é definida como:\n",
    "\n",
    "\\[ \\text{FL}(p_t) = -\\alpha_t (1 - p_t)^\\gamma \\log(p_t) \\]\n",
    "\n",
    "Onde:\n",
    "- \\( p_t \\) é a probabilidade predita para a classe verdadeira.\n",
    "- \\( \\alpha_t \\) é um fator de balanceamento entre classes (ajuda a lidar com o desequilíbrio de classes).\n",
    "- \\( \\gamma \\) (gamma) é um fator de foco que ajusta o impacto dos exemplos bem classificados (um valor maior de gamma aumenta o foco em exemplos mal classificados).\n",
    "\n",
    "#### Componentes da Focal Loss\n",
    "\n",
    "1. **Entropia Cruzada (Cross-Entropy Loss)**: A parte básica da Focal Loss é a Entropia Cruzada, que mede a diferença entre a distribuição predita e a distribuição verdadeira.\n",
    "   \\[ \\text{CE}(p_t) = -\\log(p_t) \\]\n",
    "\n",
    "2. **Termo de Ajuste \\((1 - p_t)^\\gamma\\)**: Este termo reduz a contribuição dos exemplos bem classificados. Para exemplos bem classificados, \\( p_t \\) é alto, então \\( (1 - p_t) \\) é baixo, diminuindo a perda.\n",
    "\n",
    "3. **Fator de Balanceamento (\\(\\alpha_t\\))**: Este termo ajusta a contribuição das classes, ajudando a lidar com o desequilíbrio de classes.\n",
    "   \\[ \\alpha_t \\]\n",
    "\n",
    "\n",
    "   \n",
    "#### Benefícios da Focal Loss\n",
    "\n",
    "1. **Reduz o Impacto dos Exemplos Bem Classificados**: A Focal Loss reduz a contribuição dos exemplos bem classificados, permitindo que o modelo foque mais nos exemplos difíceis e mal classificados.\n",
    "\n",
    "2. **Lida com Desequilíbrio de Classes**: A inclusão do fator de balanceamento (\\(\\alpha_t\\)) ajuda a mitigar o problema do desequilíbrio de classes, onde algumas classes podem ser muito mais frequentes do que outras.\n",
    "\n",
    "3. **Melhora a Detecção de Objetos Menores e Mais Difíceis**: Ao focar mais nos exemplos mal classificados, a Focal Loss pode ajudar a melhorar a detecção de objetos menores e mais difíceis.\n",
    "\n",
    "#### Exemplo de Implementação de Focal Loss\n",
    "\n",
    "Aqui está a implementação da Focal Loss que você utilizou no seu código:\n",
    "\n",
    "```python\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        BCE_loss = nn.functional.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-BCE_loss)  # Prevents nans when probability 0\n",
    "        F_loss = self.alpha * (1 - pt) ** self.gamma * BCE_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return torch.mean(F_loss)\n",
    "        elif self.reduction == 'sum':\n",
    "            return torch.sum(F_loss)\n",
    "        else:\n",
    "            return F_loss\n",
    "```\n",
    "### Como a Focal Loss Ajuda no Seu Caso\n",
    "\n",
    "#### No seu projeto, a Focal Loss pode ajudar das seguintes maneiras:\n",
    "\n",
    "**1. Desequilíbrio de Classes:** Se você tem classes como \"furo\" e \"veio\" que aparecem com frequências diferentes, a Focal Loss pode ajustar a contribuição dessas classes, ajudando o modelo a aprender melhor as classes menos frequentes.\n",
    "\n",
    "**2. Exemplos Difíceis:** A Focal Loss aumenta o foco nos exemplos mal classificados. Isso pode ajudar a melhorar a detecção de defeitos mais sutis ou difíceis de identificar nas chapas de granito.\n",
    "\n",
    "**3. Redução de Ruído:** Ao reduzir a contribuição dos exemplos bem classificados, a Focal Loss pode ajudar a diminuir o impacto de exemplos ruidosos ou anotações incorretas no seu dataset.\n",
    "\n",
    "**Conclusão**\n",
    "A Focal Loss é uma poderosa modificação da Entropia Cruzada que ajuda a lidar com desequilíbrios de classes e melhora o foco em exemplos difíceis, tornando-a particularmente útil em tarefas de detecção de objetos. Em seu projeto de detecção de defeitos em chapas de granito, a Focal Loss pode melhorar a precisão e a robustez do seu modelo.\n",
    "\n",
    "\n",
    "### Explicações\n",
    "\n",
    "- A Focal Loss foi desenvolvida para melhorar o desempenho em tarefas de detecção de objetos, onde o desequilíbrio de classes é um problema comum.\n",
    "- A fórmula da Focal Loss inclui um termo de ajuste que reduz a perda para exemplos bem classificados e aumenta o foco em exemplos difíceis.\n",
    "- O fator de balanceamento ajuda a mitigar problemas de desequilíbrio de classes.\n",
    "- Em seu projeto, a Focal Loss pode melhorar a detecção de defeitos menos frequentes e mais difíceis de identificar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7aa61d-8490-4c3c-a039-e8a1ccad9b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etapa 5: Configuração dos Parâmetros de Treinamento\n",
    "# Esta etapa configura os parâmetros necessários para o treinamento do modelo YOLOv8.\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import subprocess\n",
    "\n",
    "# Definição dos Parâmetros de Treinamento\n",
    "# ----------------------------------------\n",
    "\n",
    "# Caminho para o arquivo de pesos do modelo YOLOv8\n",
    "# Especifica o caminho para o arquivo de pesos pré-treinados a ser utilizado.\n",
    "model_path = \"runs/detect/train7/weights/best.pt\"\n",
    "\n",
    "# Caminho para o arquivo YAML que contém as configurações do dataset\n",
    "# Define o caminho para o arquivo YAML que configura o dataset.\n",
    "dataset_dir = \"datasets/granito-3nbcw\"  # Diretório do dataset\n",
    "data_path = os.path.join(dataset_dir, \"data.yaml\")\n",
    "\n",
    "# Número de épocas de treinamento\n",
    "# Define o número de épocas (iterações) para o treinamento do modelo.\n",
    "epochs = 50\n",
    "\n",
    "# Tamanho das imagens de entrada\n",
    "# Especifica o tamanho das imagens de entrada para o modelo.\n",
    "img_size = 640\n",
    "\n",
    "# Diretório para logs do TensorBoard\n",
    "# Obtém o diretório configurado para armazenar os logs do TensorBoard.\n",
    "settings = {'runs_dir': 'runs'}  # Configurações adicionais podem ser adicionadas aqui\n",
    "log_dir = settings.get('runs_dir', 'runs')\n",
    "\n",
    "# Configuração do dispositivo de treinamento\n",
    "# Configura o dispositivo de treinamento, utilizando 'cuda' se disponível (para GPUs NVIDIA), caso contrário, 'cpu'.\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Configuração dos parâmetros do treinamento\n",
    "# Define os parâmetros adicionais para o treinamento.\n",
    "batch_size = 16     # Define o tamanho do lote de treinamento\n",
    "workers = 8         # Define o número de workers para carregamento dos dados\n",
    "optimizer = 'auto'  # Define o otimizador. 'auto' permite ao YOLO escolher o melhor otimizador disponível\n",
    "verbose = True      # Modo verboso. Quando True, o YOLO imprime informações detalhadas durante o treinamento\n",
    "\n",
    "# Função para encontrar uma porta livre automaticamente\n",
    "# ----------------------------------------\n",
    "def find_free_port(start_port=6006, max_port=6100):\n",
    "    \"\"\"\n",
    "    Encontra uma porta livre automaticamente para iniciar o TensorBoard.\n",
    "    \n",
    "    Parâmetros:\n",
    "        start_port (int): A porta inicial para a busca.\n",
    "        max_port (int): A porta máxima para a busca.\n",
    "\n",
    "    Retorna:\n",
    "        int: Uma porta livre.\n",
    "    \"\"\"\n",
    "    import socket\n",
    "    for port in range(start_port, max_port):\n",
    "        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
    "            if s.connect_ex(('localhost', port)) != 0:\n",
    "                return port\n",
    "    raise Exception(\"No free port found\")\n",
    "\n",
    "# Encontrar uma porta livre para o TensorBoard\n",
    "tensorboard_port = find_free_port()\n",
    "\n",
    "# Inicializar o TensorBoard\n",
    "# Inicia o TensorBoard apontando para o diretório de logs configurado.\n",
    "subprocess.Popen([\n",
    "    \"tensorboard\",\n",
    "    \"--logdir\", log_dir,\n",
    "    \"--host\", \"0.0.0.0\",\n",
    "    \"--port\", str(tensorboard_port),\n",
    "    \"--reload_interval\", \"10\",\n",
    "    \"--samples_per_plugin\", \"scalars=500,images=50\",\n",
    "    \"--max_reload_threads\", \"4\",\n",
    "    \"--purge_orphaned_data\", \"true\"\n",
    "])\n",
    "\n",
    "print(f\"TensorBoard is running on port {tensorboard_port}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2075316a-e916-4238-a407-35d0ade59b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etapa 5.1: Execução do Treinamento do Modelo\n",
    "# Esta etapa executa o treinamento do modelo YOLOv8 com os parâmetros configurados anteriormente.\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import subprocess\n",
    "\n",
    "# Certifique-se de que todas as variáveis de configuração estão definidas:\n",
    "# model_path, data_path, epochs, img_size, log_dir, device, batch_size, workers, optimizer, verbose, dataset_dir\n",
    "\n",
    "# Exibir o dispositivo de treinamento\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Carregar o modelo YOLOv8\n",
    "# Carrega o modelo YOLOv8 com os pesos especificados.\n",
    "model = YOLO(model_path)\n",
    "\n",
    "# Enviar o modelo para o dispositivo especificado (cuda ou CPU)\n",
    "# Move o modelo para o dispositivo de treinamento configurado.\n",
    "model.to(device)\n",
    "\n",
    "# Verificar e criar o diretório de logs do TensorBoard, se necessário\n",
    "# Se o diretório de logs não existir, ele será criado.\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "# Iniciar o TensorBoard apontando para o diretório de logs\n",
    "# Inicia o TensorBoard para monitorar o treinamento.\n",
    "subprocess.Popen([\n",
    "    \"tensorboard\",\n",
    "    \"--logdir\", log_dir,\n",
    "    \"--host\", \"0.0.0.0\",\n",
    "    \"--port\", str(tensorboard_port),\n",
    "    \"--reload_interval\", \"10\",\n",
    "    \"--samples_per_plugin\", \"scalars=500,images=50\",\n",
    "    \"--max_reload_threads\", \"4\",\n",
    "    \"--purge_orphaned_data\", \"true\"\n",
    "])\n",
    "\n",
    "# Executar o treinamento do modelo com os parâmetros configurados\n",
    "# Inicia o processo de treinamento do modelo YOLOv8.\n",
    "results = model.train(\n",
    "    data=data_path,     # Caminho para o arquivo YAML que contém as configurações do dataset\n",
    "    epochs=epochs,      # Número de épocas de treinamento\n",
    "    imgsz=img_size,     # Tamanho das imagens de entrada\n",
    "    batch=batch_size,   # Tamanho do lote de treinamento\n",
    "    workers=workers,    # Número de workers\n",
    "    optimizer=optimizer,# Otimizador\n",
    "    verbose=verbose,    # Modo verboso\n",
    "    device=device.type  # Tipo de dispositivo como uma string\n",
    ")\n",
    "\n",
    "# Salvar o modelo treinado no diretório do dataset\n",
    "# Salva os pesos do modelo treinado no diretório especificado.\n",
    "model.save(os.path.join(dataset_dir, \"model.pt\"))\n",
    "\n",
    "# Imprimir os resultados do treinamento\n",
    "# Exibe os resultados do treinamento.\n",
    "print(\"Training completed. Results:\", results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e61248-2020-42ce-b0c3-6d9c49979782",
   "metadata": {},
   "source": [
    "## **Considerações Finais**\n",
    "\n",
    "Este projeto foi desenvolvido com o objetivo de ser replicável e fácil de entender. Cada etapa foi detalhadamente documentada para garantir que futuros usuários possam seguir o processo sem dificuldades. Se houver dúvidas ou sugestões, sinta-se à vontade para entrar em contato comigo ou com meu orientador."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
